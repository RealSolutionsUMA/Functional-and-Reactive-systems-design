%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:

\documentclass[../main.tex]{subfiles}

\begin{document}

\subsection{Improving Resilience with Computational effects}
In 1991 Eugenio Moggi [[Insert citation]] described a model in category theory
for separating the set of values a object \texttt{A} could have from the notion
of a computation of it, \texttt{T A}, which had an effect on top of this type.
This computation abstracts from the type \texttt{A} the posible results that the
computation could have. Some examples of computations mentioned on the text of
interest to this topics are.

\begin{itemize}
\item Side effects that modify an set of possible states \texttt{S}: \texttt{State[A, S]}
\item Exceptions where \texttt{E} is the set of possible exceptions: \texttt{Either[A, E]}
\item Interactive Input/Output which results in an \texttt{A} value: \texttt{IO[A]}
\end{itemize}

From a programming point of view a very interesting finding of that article is
that this effect over \texttt{A} can be abstracted and define operations that transform
the type A regardless of the effect in which it was contained as long as the
effect \texttt{F} is a monad. %% Is a monad? Has a monad?

\subsubsection{Monads}
A monad is category that provides two operations over a type constructor
\texttt{F[\_]}, \texttt{flatMap}\footnote{On literature is also usually called bind} and
\texttt{pure}\footnote{Also known as point or return}. In the following figure the a
trait that defines the Monad typeclass in Scala is defined.

[[Example]]

The semantics of the operations can be inferred by following the types of them.
The pure function takes a value \texttt{a} and lifts it to the monad context
\texttt{F}. The flatMap operation takes a monad \texttt{F[a]} and a function
which transform an \texttt{a} into a monad with the same context but a possible
different type \texttt{F[B]}. This operation mantains the monad context.

\subsection{Example of monadic effects}
Then some monads instances can be defined for different effects.

\paragraph{Option Monad}
The Option Monad is an effect which may have a value of a type \texttt{A} or
not. An \texttt{Option[A]} has two possible values. \texttt{Some} which means
that the value is present or \texttt{None} meaning that there is no value.

The function flatMap in this case returns a transformed \texttt{Some} if the monad in which
it was applied was also a \texttt{Some} or directly returns a \texttt{None} if
the monad was empty and no transformation could be applied

\paragraph{Either Monad}
When a function can either succeed or fail the Either Effect encodes this
possibility, represented with the type \texttt{Either[E, A]} it has two possible
disjoint values. Either are usually right biased, being the \texttt{A} or
``right'' value the one meaning the success and the \texttt{E} value the one
meaning an error.

\paragraph{State Monad}
The State Monad is an effect which given an state of type \texttt{S} performs an state
transition resulting in a value of type \texttt{A}, modeling an state machine.
As state cannot be mutated in place the state transation returns both the new
state and the resulting value. It can be defined this way

When using the state monad flatMap directly returns a monad with the new state
avoiding to explicitly pass the state all along the way.

\paragraph{IO Monad}
Side effects are inherently non functional. A side effect such as reading input
from the keyboard implies that every time that this operation is called the
outcome may be different, breaking referential transparency.

However if we look to the description of operations that do side effects they
have nothing that implies this lose of referential transparency. For example
the function read from keyboard whould have the type \texttt{() => A} which is a
perfectly valid type a pure function could have.

If the execution of the function with the side effect is delayed, what it
would end up being is just a description of it, without exposing its impure
nature. This is what the IO monad does. When a function is passed to the IO
the execution is suspended and the description of it is captured. It is not
until the programmer runs the descriptions wrapped in the IO Monad that the
referential transparency is lost.

If this side effect execution is delayed until the very end of programs, they
can keep functional at its core and the benefits of purity are not lost until
the interpretation of the side effects which is usually done as the last step of
the computation. Usually, in order to avoid running the execution of the side
effects manually, the entry function of the application expects an IO to be
returned which will be then be interpreted. This is exactly what the main method
of Haskell does [[Insert reference]]

\subsubsection{The resilience of computational effects}
In static typed programming languages computational effects offers a greater resilience as the
programmer has to explicitly deal with the effect and can not ignore the
effectful nature of it like having a possible error, an Either effect, or being a possibly
future value, i. e. IO.

This implicit treatment of effects like the use of a \texttt{Null} pointer has
lead to great number of mistakes, being called by one of the first designer of
it, Tony Hoare, its billion dolar mistake.

Nullability is not the only case of implicit effects. The use of unchecked
exceptions in object oriented programming languages can let errors be propagated
without the programmer supervision.

Effects are then a pattern that improve the reactiveness of functional programs by
improving the resilience with the use of the type system.

\subsection{Leveraging Multiprocessing by the use of Futures}
Futures, also called Promises, model an asynchronous computational model in
which operations can be ran in a separate thead of execution from the calling
thread of the future itself.

A Future can be created using the \texttt{apply} method of the companion object
of the trait \texttt{Future}. An invocation have this form
\texttt{Future(\textit{expr})}. This would evaluate expr in the background. The
call returns immediatly with a result of type Future[A], being A the result type
of the expression \texttt{\textit{expr}}.

\subsubsection{Making models reactive by the use of Futures}

Computations that could block the thread of execution, e.g. Blocking I/O like
fetching a resource through the network, should be ran inside Futures. This
contributes to the overall application reactiveness by terms of responsivenes by
improving the overall request latency and by reducing the load of the main
execution thread.

\paragraph{Latency improvements of futures}

By spawning blocking calls in separate threads of execution the response time of
a request transitions from being the sum of the latencies of the independent
blocking operations to the latency of the longest one. This is represented in
figure \ref{fig:futurelatency}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{futurelatency.png}
  \caption{\label{fig:futurelatency}
    At the left of the figure a sequential run of the blocking operations. At
    the right a parallel execution which combines the results
  }
\end{figure}

\subsubsection{Futures are highly composable}
Futures are designed to be composable. Instead of transforming the result of the
future by waiting for the completion of the inner expression to be completed
method of a \texttt{Future[A]} allow to transform it by passing description of what
should be done once the Future is completed this methods don't block until the
future is complete but return a \texttt{Future[B]} being \texttt{B} the type of the transformed
value from \texttt{A}.

\paragraph{Freeing the load of the main thread of execution}

In web servers there is usually a fixed thread pool for handling requests. This
thread pool has a maximum number of threads available to prevent the systems
from collapsing. In tomcat for example when this threshold is surpassed no more
request can be met and the request start to be stacked. Moment in which latency
starts to increase in a great manner.

Futures have an implicit parameter which defines the execution context in which
the future expression will be ran. [[cite execution context from API]]. An
execution context may have associated an specific thread pool. This can be used
for making the blocking calls to be executed in a separate pool for blocking
tasks, freeing the main thread thread pool which is only responsible of spawning the tasks
of Futures, but not of running them.

\subsection{The IO monad as a referential transparent Future}
Future has many properties that make it an appropiate construct for modeling
asynchronous operations. However its operations are not referential transparent.
By the definition of
it, if Future was referentially transparent the result of the operations on a
Future should be the same regardless if they operation functions were composed
directly or if by saved in variables.

\lstinputlisting[
caption=An example of how Future is not referentially transparent,
captionpos=b,
label={lst:impurefuture}
]{ImpureFuture.sc}

This lack of referential transparency is shown in Listing \ref{lst:impurefuture}. Two
future variables are created on the top level \texttt{futureByVariable} and
\texttt{futureByComposition}. This futures are created by composing two futures
created by the same operation, \texttt{random.nextInt}. However in
\texttt{futureByVariable} as \texttt{Future} caches the results of the function
which was ran on it the operation isn't performed the second time, this caching
is a indeed as a side effect given that a variable with the result value has to
be updated once the operation has been performed.

The IO Monad does not perform this caching and it is possible to save it into a
variable without losing referential transparency as Listing \ref{lst:pureio}

\lstinputlisting[
caption=The IO Monad does not cache values and is referentially transparent,
captionpos=b,
label={lst:pureio}
]{PureIO.sc}

\end{document}